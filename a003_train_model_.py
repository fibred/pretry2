# -*- coding: utf-8 -*-
"""a004_train_model .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K6f0G0_3EWS6aCAC4E5hPVDVUpmMsZ6g
"""

from PIL import Image
from tensorflow.keras import backend as K
from tensorflow.keras.utils import plot_model

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model, Model
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split

import os
import cv2 as cv
import glob
import pickle

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

CAPTCHA_CHARSET = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',
            'v', 'w', 'x', 'y', 'z', ]   # 驗證碼字符集
CAPTCHA_LEN = 4            # 驗證碼長度
CAPTCHA_HEIGHT =  35            # 驗證碼高度
CAPTCHA_WIDTH =   68           # 驗證碼寬度

TRAIN_DATA_DIR = '../datas/train/' # 驗證碼數據集目錄
TEST_DATA_DIR = '../datas/test/' # 數據集目錄

BATCH_SIZE = 100
EPOCHS = 100
OPT = 'adam'

MODEL_DIR = 'models/train_demo/'
MODEL_FORMAT = '.h5'
HISTORY_DIR = 'models/history/'
HISTORY_FORMAT = '.history'

filename_str = "{}captcha_{}_{}_bs_{}_epochs_{}{}"

# 模型網絡結構文件
MODEL_VIS_FILE = 'captcha_classfication' + '.png'
# 模型文件
MODEL_FILE = filename_str.format(MODEL_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), MODEL_FORMAT)
# 訓練記錄文件
HISTORY_FILE = filename_str.format(HISTORY_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), HISTORY_FORMAT)

def rgb2gray(img):
    # Y' = 0.299 R + 0.587 G + 0.114 B 
    return np.dot(img[...,:3], [0.299, 0.587, 0.114])

# 定義one-hot編碼函數

def text2vec(text,length=CAPTCHA_LEN,charset=CAPTCHA_CHARSET):
    text_len = len(text)
    # 驗證碼長度校驗
    if text_len != length:
        raise ValueError("Error:length of captcha should be{},but got {}".format(length,text_len))
    # 生成一個形如(CAPTCHA_LEN*CAPTCHA_CHARSET)的一維向量
    # 例如，4個純數字的驗證碼生成形如(4*10,)的一維向量
    vec = np.zeros(length*len(charset)) #生成一个默认为0的向量
    for i in range(length):
        # One-hot編碼驗證碼中的每個數字
        # 每個字符的熱碼 = 索引 +偏移量
        vec[charset.index(text[i]) + i*len(charset)] = 1
    return vec

# 向量转回文本

def vec2text(vector):
    if not isinstance(vector, np.ndarray):
        vector = np.asarray(vector)
    vector = np.reshape(vector, [CAPTCHA_LEN, -1])
    text = ''
    for item in vector:
        text += CAPTCHA_CHARSET[np.argmax(item)]
    return text

def fit_keras_channels(batch, rows=CAPTCHA_HEIGHT, cols=CAPTCHA_WIDTH):
    if K.image_data_format() == 'channels_first':
        batch = batch.reshape(batch.shape[0], 1, rows, cols)
        input_shape = (1, rows, cols)
    else:
        batch = batch.reshape(batch.shape[0], rows, cols, 1)
        input_shape = (rows, cols, 1)
    
    return batch, input_shape

X_train = []
Y_train = []
Y_filename = []
for filename in glob.glob(TRAIN_DATA_DIR + "*.jpg"):
    X_train.append(np.array(Image.open(filename)))
    Y_filename.append(filename)
#    Y_train.append(filename.lstrip("datas/train\\").rstrip(".png"))
for filename in glob.glob(TRAIN_DATA_DIR + "*.png"):
    X_train.append(np.array(Image.open(filename)))
    Y_filename.append(filename)

# list -> rgb(numpy)
X_train = np.array(X_train, dtype=np.float32)
# rgb -> gray
X_train = rgb2gray(X_train)
# normalize
X_train = X_train / 255
# Fit keras channels
X_train, input_shape = fit_keras_channels(X_train)

print(X_train.shape, type(X_train))
print(input_shape)

for i in range(len(Y_filename)):
    Y_train.append(Y_filename[i][-8:-4])
for i in range(len(Y_train)):
    Y_train[i] = text2vec(Y_train[i])

Y_train = np.asarray(Y_train)
print(Y_train.shape, type(Y_train))
print(Y_train[0])

Y_train.shape

X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)

X_train.shape, X_val.shape, Y_train.shape, Y_val.shape

load_model_name = "0807_2"
load_model_path = './models/{}.h5'.format(load_model_name)
model_name = "0808_1"
model_path = './models/{}.h5'.format(model_name)

try:
    model = load_model(load_model_path)
except Exception as e:
    print('##Exception', e)
    model = crack_captcha_cnn()

# 輸入層
inputs = Input(shape = input_shape,name = "inputs")


# 第1層卷積
conv1 = Conv2D(32,(3,3),name="conv1")(inputs)
relu1 = Activation("relu",name="relu1")(conv1)

# 第2層卷積
conv2 = Conv2D(128,(5,5),name ="conv2")(relu1)
relu2 = Activation("relu",name="relu2")(conv2)
pool2 = MaxPooling2D(pool_size=(2,2),padding="same",name="pool2")(relu2)

# 第3層卷積
conv3 = Conv2D(256,(5,5),name="conv3")(pool2)
relu3 = Activation("relu",name="relu3")(conv3)
pool3 = MaxPooling2D(pool_size=(2,2),padding="same",name="pool3")(relu3)

# 將Pooled feature map 攤平後輸入全連接網絡
x = Flatten()(pool3)

# Dropout
#x = Dropout(0.25)(x)

# 4個全連接層分別做10分類，分別對應4個字符
x = [Dense(36,activation="softmax",name="fc%d"%(i+1))(x) for i in range(4)]

# 4個字符向量拼接在一起，與標籤向量形式一致，作爲模型輸出
outs = Concatenate()(x)

# 定義模型的輸入與輸出
model = Model(inputs=inputs,outputs=outs)
optimizer = keras.optimizers.Adam(lr=10e-6)
model.compile(#loss=LOSS,
    loss='categorical_crossentropy',
              optimizer=optimizer, metrics=['accuracy'])

print(model.summary())

plot_model(model,show_shapes=True)

datagen = ImageDataGenerator(
    rotation_range=0.01,
    width_shift_range=0.001,
    height_shift_range=0.01,
    shear_range=0.01,
#    zoom_range=0.2,
    horizontal_flip=False,
    channel_shift_range=15,
#    cval=0,
#    zca_epsilon=1e-6,
    fill_mode='nearest'
)



optimizer = keras.optimizers.Adam(lr=10e-4)

model_path = './models/{}.h5'.format(model_name)
checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)
earlystop = EarlyStopping(monitor='val_loss', patience=20, verbose=1)

model.compile(optimizer=optimizer, 
              loss='categorical_crossentropy',
 #             loss= 'binary_crossentropy',
              
              metrics=['accuracy'])


batch_size = 16
epochs = 200

history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size),
                              epochs = epochs,
                              validation_data = (X_val, Y_val),
                             callbacks = [checkpoint, earlystop]
                             )



model_history = history

training_loss = model_history.history['loss']
val_loss = model_history.history['val_loss']

plt.plot(training_loss, label="training_loss")
plt.plot(val_loss, label="validation_loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Learning Curve")
plt.legend(loc='best')
plt.show()

training_acc = model_history.history['accuracy']
val_acc = model_history.history['val_accuracy']

plt.plot(training_acc, label="training_acc")
plt.plot(val_acc, label="validation_acc")
plt.xlabel("Epochs")
plt.ylabel("Acc")
plt.title("Learning Curve")
plt.legend(loc='best')
plt.show()

model = load_model(model_path)

scores = model.evaluate(X_val, Y_val, verbose=1)
print('Validation loss:', scores[0])
print('Validation accuracy:', scores[1])



