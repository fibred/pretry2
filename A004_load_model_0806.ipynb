{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTCHA_CHARSET = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9','a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z', ]   # 驗證碼字符集\n",
    "CAPTCHA_LEN = 4            # 驗證碼長度\n",
    "CAPTCHA_HEIGHT =  35            # 驗證碼高度\n",
    "CAPTCHA_WIDTH =   68           # 驗證碼寬度\n",
    "\n",
    "TRAIN_DATA_DIR = 'datas/train/' # 驗證碼數據集目錄\n",
    "TEST_DATA_DIR = 'datas/test/' # 數據集目錄\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 100\n",
    "OPT = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "\n",
    "MODEL_DIR = 'models/train_demo/'\n",
    "MODEL_FORMAT = '.h5'\n",
    "HISTORY_DIR = 'models/history/'\n",
    "HISTORY_FORMAT = '.history'\n",
    "\n",
    "filename_str = \"{}captcha_{}_{}_bs_{}_epochs_{}{}\"\n",
    "\n",
    "# 模型網絡結構文件\n",
    "MODEL_VIS_FILE = 'captcha_classfication' + '.png'\n",
    "# 模型文件\n",
    "MODEL_FILE = filename_str.format(MODEL_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), MODEL_FORMAT)\n",
    "# 訓練記錄文件\n",
    "HISTORY_FILE = filename_str.format(HISTORY_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), HISTORY_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(img):\n",
    "    # Y' = 0.299 R + 0.587 G + 0.114 B \n",
    "    return np.dot(img[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義one-hot編碼函數\n",
    "\n",
    "def text2vec(text,length=CAPTCHA_LEN,charset=CAPTCHA_CHARSET):\n",
    "    text_len = len(text)\n",
    "    # 驗證碼長度校驗\n",
    "    if text_len != length:\n",
    "        raise ValueError(\"Error:length of captcha should be{},but got {}\".format(length,text_len))\n",
    "    # 生成一個形如(CAPTCHA_LEN*CAPTCHA_CHARSET)的一維向量\n",
    "    # 例如，4個純數字的驗證碼生成形如(4*10,)的一維向量\n",
    "    vec = np.zeros(length*len(charset)) #生成一个默认为0的向量\n",
    "    for i in range(length):\n",
    "        # One-hot編碼驗證碼中的每個數字\n",
    "        # 每個字符的熱碼 = 索引 +偏移量\n",
    "        vec[charset.index(text[i]) + i*len(charset)] = 1\n",
    "    return vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量转回文本\n",
    "\n",
    "def vec2text(vector):\n",
    "    if not isinstance(vector, np.ndarray):\n",
    "        vector = np.asarray(vector)\n",
    "    vector = np.reshape(vector, [CAPTCHA_LEN, -1])\n",
    "    text = ''\n",
    "    for item in vector:\n",
    "        text += CAPTCHA_CHARSET[np.argmax(item)]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_keras_channels(batch, rows=CAPTCHA_HEIGHT, cols=CAPTCHA_WIDTH):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        batch = batch.reshape(batch.shape[0], 1, rows, cols)\n",
    "        input_shape = (1, rows, cols)\n",
    "    else:\n",
    "        batch = batch.reshape(batch.shape[0], rows, cols, 1)\n",
    "        input_shape = (rows, cols, 1)\n",
    "    \n",
    "    return batch, input_shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#binary\n",
    "\n",
    "def method_1(image):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "    t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    return binary\n",
    "\n",
    "\n",
    "def method_2(image):\n",
    "    blurred = cv.GaussianBlur(image, (3, 3), 0)\n",
    "    gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY)\n",
    "    t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    return binary\n",
    "\n",
    "\n",
    "def method_3(image):\n",
    "    blurred = cv.pyrMeanShiftFiltering(image, 10, 50)\n",
    "    gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY)\n",
    "    t, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_OTSU)\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "Y_filename = []\n",
    "for filename in glob.glob(TRAIN_DATA_DIR + \"*.jpg\"):\n",
    "    X_train.append(np.array(Image.open(filename)))\n",
    "    Y_filename.append(filename)\n",
    "#    Y_train.append(filename.lstrip(\"datas/train\\\\\").rstrip(\".png\"))\n",
    "for filename in glob.glob(TRAIN_DATA_DIR + \"*.png\"):\n",
    "    X_train.append(np.array(Image.open(filename)))\n",
    "    Y_filename.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7530, 35, 68, 1) <class 'numpy.ndarray'>\n",
      "(35, 68, 1)\n"
     ]
    }
   ],
   "source": [
    "# list -> rgb(numpy)\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "# rgb -> gray\n",
    "X_train = rgb2gray(X_train)\n",
    "# normalize\n",
    "X_train = X_train / 255\n",
    "# Fit keras channels\n",
    "X_train, input_shape = fit_keras_channels(X_train)\n",
    "\n",
    "print(X_train.shape, type(X_train))\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_filename)):\n",
    "    Y_train.append(Y_filename[i][12:16])\n",
    "for i in range(len(Y_train)):\n",
    "    Y_train[i] = text2vec(Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7530, 144) <class 'numpy.ndarray'>\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.asarray(Y_train)\n",
    "print(Y_train.shape, type(Y_train))\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7530, 144)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6777, 35, 68, 1), (753, 35, 68, 1), (6777, 144), (753, 144))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_name = \"0806_2\"\n",
    "load_model_path = './models/{}.h5'.format(load_model_name)\n",
    "model_name = \"0806_3\"\n",
    "model_path = './models/{}.h5'.format(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = load_model(load_model_path)\n",
    "except Exception as e:\n",
    "    print('#######Exception', e)\n",
    "    model = crack_captcha_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入層\n",
    "inputs = Input(shape = input_shape,name = \"inputs\")\n",
    "\n",
    "\n",
    "# 第1層卷積\n",
    "conv1 = Conv2D(32,(3,3),name=\"conv1\")(inputs)\n",
    "relu1 = Activation(\"relu\",name=\"relu1\")(conv1)\n",
    "\n",
    "# 第2層卷積\n",
    "conv2 = Conv2D(128,(5,5),name =\"conv2\")(relu1)\n",
    "relu2 = Activation(\"relu\",name=\"relu2\")(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2),padding=\"same\",name=\"pool2\")(relu2)\n",
    "\n",
    "# 第3層卷積\n",
    "conv3 = Conv2D(256,(5,5),name=\"conv3\")(pool2)\n",
    "relu3 = Activation(\"relu\",name=\"relu3\")(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2),padding=\"same\",name=\"pool3\")(relu3)\n",
    "\n",
    "# 將Pooled feature map 攤平後輸入全連接網絡\n",
    "x = Flatten()(pool3)\n",
    "\n",
    "# Dropout\n",
    "#x = Dropout(0.25)(x)\n",
    "\n",
    "# 4個全連接層分別做10分類，分別對應4個字符\n",
    "x = [Dense(36,activation=\"softmax\",name=\"fc%d\"%(i+1))(x) for i in range(4)]\n",
    "\n",
    "# 4個字符向量拼接在一起，與標籤向量形式一致，作爲模型輸出\n",
    "outs = Concatenate()(x)\n",
    "\n",
    "# 定義模型的輸入與輸出\n",
    "model = Model(inputs=inputs,outputs=outs)\n",
    "optimizer = keras.optimizers.Adam(lr=10e-6)\n",
    "model.compile(#loss=LOSS,\n",
    "    loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 35, 68, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 33, 66, 32)   320         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 33, 66, 32)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 29, 62, 128)  102528      relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu2 (Activation)              (None, 29, 62, 128)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 15, 31, 128)  0           relu2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 11, 27, 256)  819456      pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu3 (Activation)              (None, 11, 27, 256)  0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 6, 14, 256)   0           relu3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 21504)        0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 36)           774180      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc2 (Dense)                     (None, 36)           774180      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc3 (Dense)                     (None, 36)           774180      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "fc4 (Dense)                     (None, 36)           774180      flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 144)          0           fc1[0][0]                        \n",
      "                                                                 fc2[0][0]                        \n",
      "                                                                 fc3[0][0]                        \n",
      "                                                                 fc4[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 4,019,024\n",
      "Trainable params: 4,019,024\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9737\n",
      "Epoch 00001: val_loss improved from inf to 0.02852, saving model to ./models/0806_3.h5\n",
      "424/424 [==============================] - 226s 533ms/step - loss: 0.1120 - accuracy: 0.9737 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
      "Epoch 2/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9738\n",
      "Epoch 00002: val_loss improved from 0.02852 to 0.02610, saving model to ./models/0806_3.h5\n",
      "424/424 [==============================] - 226s 533ms/step - loss: 0.1115 - accuracy: 0.9738 - val_loss: 0.0261 - val_accuracy: 0.9918\n",
      "Epoch 3/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9738\n",
      "Epoch 00003: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 532ms/step - loss: 0.1118 - accuracy: 0.9738 - val_loss: 0.0278 - val_accuracy: 0.9920\n",
      "Epoch 4/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9738\n",
      "Epoch 00004: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 533ms/step - loss: 0.1115 - accuracy: 0.9738 - val_loss: 0.0288 - val_accuracy: 0.9919\n",
      "Epoch 5/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9737\n",
      "Epoch 00005: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 533ms/step - loss: 0.1118 - accuracy: 0.9737 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 6/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9738\n",
      "Epoch 00006: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 532ms/step - loss: 0.1114 - accuracy: 0.9738 - val_loss: 0.0289 - val_accuracy: 0.9921\n",
      "Epoch 7/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9738\n",
      "Epoch 00007: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 534ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 0.0294 - val_accuracy: 0.9923\n",
      "Epoch 8/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9738\n",
      "Epoch 00008: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 227s 536ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 0.0270 - val_accuracy: 0.9919\n",
      "Epoch 9/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1123 - accuracy: 0.9736\n",
      "Epoch 00009: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 226s 534ms/step - loss: 0.1123 - accuracy: 0.9736 - val_loss: 0.0292 - val_accuracy: 0.9919\n",
      "Epoch 10/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9738\n",
      "Epoch 00010: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 227s 535ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 0.0282 - val_accuracy: 0.9922\n",
      "Epoch 11/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1114 - accuracy: 0.9739\n",
      "Epoch 00011: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 229s 540ms/step - loss: 0.1113 - accuracy: 0.9739 - val_loss: 0.0279 - val_accuracy: 0.9919\n",
      "Epoch 12/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9738\n",
      "Epoch 00012: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 227s 536ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 0.0281 - val_accuracy: 0.9921\n",
      "Epoch 13/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1115 - accuracy: 0.9738\n",
      "Epoch 00013: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 227s 535ms/step - loss: 0.1115 - accuracy: 0.9738 - val_loss: 0.0342 - val_accuracy: 0.9912\n",
      "Epoch 14/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1119 - accuracy: 0.9737\n",
      "Epoch 00014: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 227s 535ms/step - loss: 0.1119 - accuracy: 0.9737 - val_loss: 0.0295 - val_accuracy: 0.9918\n",
      "Epoch 15/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9738\n",
      "Epoch 00015: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 242s 571ms/step - loss: 0.1119 - accuracy: 0.9738 - val_loss: 0.0287 - val_accuracy: 0.9916\n",
      "Epoch 16/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1110 - accuracy: 0.9739\n",
      "Epoch 00016: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 234s 552ms/step - loss: 0.1110 - accuracy: 0.9739 - val_loss: 0.0335 - val_accuracy: 0.9918\n",
      "Epoch 17/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9738\n",
      "Epoch 00017: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 235s 555ms/step - loss: 0.1118 - accuracy: 0.9738 - val_loss: 0.0285 - val_accuracy: 0.9921\n",
      "Epoch 18/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1113 - accuracy: 0.9739\n",
      "Epoch 00018: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 234s 551ms/step - loss: 0.1113 - accuracy: 0.9739 - val_loss: 0.0323 - val_accuracy: 0.9904\n",
      "Epoch 19/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9738\n",
      "Epoch 00019: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 235s 553ms/step - loss: 0.1117 - accuracy: 0.9738 - val_loss: 0.0316 - val_accuracy: 0.9923\n",
      "Epoch 20/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9738\n",
      "Epoch 00020: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 238s 561ms/step - loss: 0.1117 - accuracy: 0.9738 - val_loss: 0.0318 - val_accuracy: 0.9921\n",
      "Epoch 21/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9738\n",
      "Epoch 00021: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 228s 537ms/step - loss: 0.1116 - accuracy: 0.9738 - val_loss: 0.0355 - val_accuracy: 0.9916\n",
      "Epoch 22/200\n",
      "423/424 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9739\n",
      "Epoch 00022: val_loss did not improve from 0.02610\n",
      "424/424 [==============================] - 229s 541ms/step - loss: 0.1112 - accuracy: 0.9739 - val_loss: 0.0349 - val_accuracy: 0.9918\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "#    rotation_range=0.01,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01,\n",
    "    shear_range=0.001,\n",
    "#    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    channel_shift_range=10,\n",
    "#    cval=0,\n",
    "#    zca_epsilon=1e-6,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=10e-4)\n",
    "\n",
    "model_path = './models/{}.h5'.format(model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "#              loss='categorical_crossentropy',\n",
    "              loss= LOSS,\n",
    "              \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size = batch_size),\n",
    "                              epochs = epochs,\n",
    "                              validation_data = (X_val, Y_val),\n",
    "                             callbacks = [checkpoint, earlystop]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = history\n",
    "\n",
    "training_loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.plot(training_loss, label=\"training_loss\")\n",
    "plt.plot(val_loss, label=\"validation_loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "plt.plot(training_acc, label=\"training_acc\")\n",
    "plt.plot(val_acc, label=\"validation_acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Acc\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path)\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []\n",
    "Y_testfilename = []\n",
    "for filename in glob.glob(TEST_DATA_DIR + \"*.jpg\"):\n",
    "    X_test.append(np.array(Image.open(filename)))\n",
    "    Y_testfilename.append(filename)\n",
    "#    Y_train.append(filename.lstrip(\"datas/train\\\\\").rstrip(\".png\"))\n",
    "for filename in glob.glob(TEST_DATA_DIR + \"*.png\"):\n",
    "    X_test.append(np.array(Image.open(filename)))\n",
    "    Y_testfilename.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 35, 68, 1) <class 'numpy.ndarray'>\n",
      "(35, 68, 1)\n"
     ]
    }
   ],
   "source": [
    "# list -> rgb(numpy)\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "# rgb -> gray\n",
    "X_test = rgb2gray(X_test)\n",
    "# normalize\n",
    "X_test = X_test / 255\n",
    "# Fit keras channels\n",
    "X_test, input_shape = fit_keras_channels(X_test)\n",
    "\n",
    "print(X_test.shape, type(X_test))\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_testfilename)):\n",
    "    Y_test.append(Y_testfilename[i][11:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y_test)):\n",
    "    Y_test[i] = text2vec(Y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 144) <class 'numpy.ndarray'>\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.asarray(Y_test)\n",
    "print(Y_test.shape, type(Y_test))\n",
    "print(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3adc'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec2text(Y_test[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test\n",
    "X_id = Y_test\n",
    "\n",
    "model_name = \"0806_2\"\n",
    "model_path = './models/{}.h5'.format(model_name)\n",
    "model = load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.5220783e-22, 6.3255320e-22, 9.9980253e-01, ..., 7.7217908e-07,\n",
       "        2.8623782e-07, 3.6055965e-08],\n",
       "       [4.2497086e-18, 2.7107968e-18, 9.8203421e-01, ..., 7.9522779e-09,\n",
       "        2.2685040e-10, 4.1856758e-05],\n",
       "       [3.2262162e-22, 3.4298120e-22, 9.9998415e-01, ..., 2.9481944e-07,\n",
       "        6.3760645e-08, 2.8121911e-13],\n",
       "       ...,\n",
       "       [5.7013243e-23, 7.5167539e-23, 1.9867988e-03, ..., 3.1421424e-11,\n",
       "        1.3047622e-05, 2.9318370e-20],\n",
       "       [6.9136401e-18, 6.5181443e-18, 4.8938729e-03, ..., 3.7162674e-06,\n",
       "        9.4698113e-01, 2.6321171e-11],\n",
       "       [1.4219442e-20, 1.3783637e-20, 2.9486281e-01, ..., 3.0089883e-05,\n",
       "        4.5823079e-09, 1.1636355e-06]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_prob = model.predict(X_test)\n",
    "y_test_pred = []\n",
    "for i in range(len(y_test_pred_prob)):\n",
    "    y_test_pred.append(vec2text(y_test_pred_prob[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['237j',\n",
       " '24je',\n",
       " '25r7',\n",
       " '26df',\n",
       " '28r5',\n",
       " '2a8c',\n",
       " '2a8f',\n",
       " '2aet',\n",
       " '2crr',\n",
       " '2g33',\n",
       " '2hk2',\n",
       " '2r43',\n",
       " '2u65',\n",
       " '2xa3',\n",
       " '2zc2',\n",
       " '35jf',\n",
       " '36g7',\n",
       " '378c',\n",
       " '37tr',\n",
       " '3959',\n",
       " '3adc',\n",
       " '3gkf',\n",
       " '3hb3',\n",
       " '3xyq',\n",
       " '448q',\n",
       " '47xh',\n",
       " '47zh',\n",
       " '4a29',\n",
       " '4a65',\n",
       " '4cse',\n",
       " '4dre',\n",
       " '4dxs',\n",
       " '4e9a',\n",
       " '4g2y',\n",
       " '4jz6',\n",
       " '4ktz',\n",
       " '4p6g',\n",
       " '4q62',\n",
       " '4qdf',\n",
       " '4r2z',\n",
       " '4rj7',\n",
       " '4s2u',\n",
       " '4sak',\n",
       " '4t4e',\n",
       " '548u',\n",
       " '577p',\n",
       " '58y9',\n",
       " '5arj',\n",
       " '5epp',\n",
       " '5h5y',\n",
       " '5qhr',\n",
       " '5rjb',\n",
       " '5sds',\n",
       " '5uzc',\n",
       " '5z8h',\n",
       " '63kt',\n",
       " '63xg',\n",
       " '649p',\n",
       " '65b4',\n",
       " '6754',\n",
       " '67db',\n",
       " '67e3',\n",
       " '68q7',\n",
       " '69g2',\n",
       " '6c2h',\n",
       " '6dgc',\n",
       " '6e7h',\n",
       " '6ecz',\n",
       " '6f5f',\n",
       " '6gkf',\n",
       " '6kbc',\n",
       " '6r9b',\n",
       " '6rs8',\n",
       " '6y8k',\n",
       " '6zrf',\n",
       " '7857',\n",
       " '78ay',\n",
       " '78f2',\n",
       " '78sr',\n",
       " '7b38',\n",
       " '7d8d',\n",
       " '7eg3',\n",
       " '7g8b',\n",
       " '7hkb',\n",
       " '7kgr',\n",
       " '7kut',\n",
       " '7p33',\n",
       " '7p7u',\n",
       " '7r3t',\n",
       " '7sur',\n",
       " '7th7',\n",
       " '7zes',\n",
       " '83gd',\n",
       " '83h4',\n",
       " '854y',\n",
       " '8ak9',\n",
       " '8b49',\n",
       " '8bzb',\n",
       " '8cz7',\n",
       " '8ecs',\n",
       " '8fhj',\n",
       " '8fsd',\n",
       " '8h2p',\n",
       " '8jkx',\n",
       " '8js4',\n",
       " '8kdg',\n",
       " '8q6a',\n",
       " '8q7u',\n",
       " '8rrk',\n",
       " '8s5t',\n",
       " '8u6p',\n",
       " '8x9k',\n",
       " '8xzp',\n",
       " '8y9f',\n",
       " '8ygj',\n",
       " '95p4',\n",
       " '9dhe',\n",
       " '9hkr',\n",
       " '9tk3',\n",
       " '9tkp',\n",
       " '9z7f',\n",
       " 'a2jr',\n",
       " 'a64z',\n",
       " 'a7eg',\n",
       " 'a9ut',\n",
       " 'abk3',\n",
       " 'acxp',\n",
       " 'ad7e',\n",
       " 'ae7z',\n",
       " 'aear',\n",
       " 'ajpp',\n",
       " 'ajty',\n",
       " 'ak2f',\n",
       " 'arcp',\n",
       " 'asr3',\n",
       " 'asxj',\n",
       " 'atpp',\n",
       " 'ax7g',\n",
       " 'b2ey',\n",
       " 'b3hx',\n",
       " 'b4p9',\n",
       " 'b54e',\n",
       " 'b6zu',\n",
       " 'ba3t',\n",
       " 'bbat',\n",
       " 'bc4c',\n",
       " 'bc6c',\n",
       " 'bcfc',\n",
       " 'bdbp',\n",
       " 'betp',\n",
       " 'bfrx',\n",
       " 'brt5',\n",
       " 'bxye',\n",
       " 'by7h',\n",
       " 'c2ad',\n",
       " 'c4jp',\n",
       " 'c8rz',\n",
       " 'c9gh',\n",
       " 'c9qd',\n",
       " 'c9sa',\n",
       " 'cakp',\n",
       " 'cbue',\n",
       " 'ccfr',\n",
       " 'ccpk',\n",
       " 'ce2x',\n",
       " 'cfg5',\n",
       " 'cfsk',\n",
       " 'cjsy',\n",
       " 'cqeu',\n",
       " 'crjx',\n",
       " 'csr5',\n",
       " 'cypx',\n",
       " 'd2sr',\n",
       " 'd38c',\n",
       " 'd5cy',\n",
       " 'd5xp',\n",
       " 'd8yh',\n",
       " 'd93z',\n",
       " 'dbg3',\n",
       " 'dbhx',\n",
       " 'dgs4',\n",
       " 'dhfh',\n",
       " 'dj6q',\n",
       " 'dju5',\n",
       " 'dpfg',\n",
       " 'dqtr',\n",
       " 'dqxt',\n",
       " 'dqz5',\n",
       " 'dsjt',\n",
       " 'dtja',\n",
       " 'dyc4',\n",
       " 'dz75',\n",
       " 'e468',\n",
       " 'e6kk',\n",
       " 'ebku',\n",
       " 'ed9p',\n",
       " 'efea',\n",
       " 'efj7',\n",
       " 'eg64',\n",
       " 'ejz6',\n",
       " 'ek3b',\n",
       " 'ekjp',\n",
       " 'ekt3',\n",
       " 'eqta',\n",
       " 'es6c',\n",
       " 'eu76',\n",
       " 'eu8r',\n",
       " 'ex69',\n",
       " 'exex',\n",
       " 'f2f7',\n",
       " 'fb73',\n",
       " 'fcs2',\n",
       " 'fhuq',\n",
       " 'fk8s',\n",
       " 'fkkf',\n",
       " 'frgy',\n",
       " 'fxr6',\n",
       " 'fydj',\n",
       " 'fyhj',\n",
       " 'g4uz',\n",
       " 'g837',\n",
       " 'g87c',\n",
       " 'g9bp',\n",
       " 'gbg9',\n",
       " 'gbyp',\n",
       " 'gc6g',\n",
       " 'ge5k',\n",
       " 'ge7z',\n",
       " 'ggue',\n",
       " 'gj3a',\n",
       " 'gk6t',\n",
       " 'gphp',\n",
       " 'grhs',\n",
       " 'gtkz',\n",
       " 'gtt8',\n",
       " 'guku',\n",
       " 'h2ak',\n",
       " 'h52h',\n",
       " 'h5tf',\n",
       " 'h67g',\n",
       " 'h6qb',\n",
       " 'h8xp',\n",
       " 'ha5j',\n",
       " 'hc6y',\n",
       " 'hcxh',\n",
       " 'hdq6',\n",
       " 'heqe',\n",
       " 'hey8',\n",
       " 'hh3j',\n",
       " 'hr2k',\n",
       " 'hxud',\n",
       " 'hyjx',\n",
       " 'j2z7',\n",
       " 'j3xy',\n",
       " 'j42r',\n",
       " 'j44d',\n",
       " 'j4z4',\n",
       " 'j899',\n",
       " 'j8uc',\n",
       " 'jb2e',\n",
       " 'jbgk',\n",
       " 'jc2b',\n",
       " 'jes5',\n",
       " 'jetc',\n",
       " 'jkuc',\n",
       " 'js3t',\n",
       " 'ju8f',\n",
       " 'k4t8',\n",
       " 'k5q7',\n",
       " 'k6b5',\n",
       " 'k9bd',\n",
       " 'kafq',\n",
       " 'kbyk',\n",
       " 'kc2d',\n",
       " 'keeq',\n",
       " 'kkc8',\n",
       " 'kprz',\n",
       " 'kq9e',\n",
       " 'krej',\n",
       " 'kucg',\n",
       " 'p3jj',\n",
       " 'p5a9',\n",
       " 'p87g',\n",
       " 'pdte',\n",
       " 'pf2f',\n",
       " 'pj4f',\n",
       " 'pj6a',\n",
       " 'prtd',\n",
       " 'puhf',\n",
       " 'pxh5',\n",
       " 'pzt7',\n",
       " 'q4f2',\n",
       " 'q4ut',\n",
       " 'q5yj',\n",
       " 'q8zx',\n",
       " 'qaah',\n",
       " 'qaet',\n",
       " 'qb7x',\n",
       " 'qcue',\n",
       " 'qd7d',\n",
       " 'qg96',\n",
       " 'qh5s',\n",
       " 'qhak',\n",
       " 'qk5p',\n",
       " 'qtka',\n",
       " 'qtrx',\n",
       " 'qu2g',\n",
       " 'qu8b',\n",
       " 'qx9q',\n",
       " 'qxpx',\n",
       " 'r2hh',\n",
       " 'r34u',\n",
       " 'r4h8',\n",
       " 'r4k5',\n",
       " 'r62c',\n",
       " 'r987',\n",
       " 'rag2',\n",
       " 'rcs6',\n",
       " 'rf48',\n",
       " 'rfe7',\n",
       " 'rg44',\n",
       " 'rgey',\n",
       " 'rhgp',\n",
       " 'rhpb',\n",
       " 'rhps',\n",
       " 'rsft',\n",
       " 'rte2',\n",
       " 'ryhu',\n",
       " 'rzeb',\n",
       " 's46s',\n",
       " 's48t',\n",
       " 's5bb',\n",
       " 's5bj',\n",
       " 's743',\n",
       " 's7s3',\n",
       " 's83g',\n",
       " 's9cf',\n",
       " 'sbbz',\n",
       " 'sj2s',\n",
       " 'spu7',\n",
       " 'sqb3',\n",
       " 'ss6k',\n",
       " 'sxhs',\n",
       " 'sy3u',\n",
       " 'sz6k',\n",
       " 't47e',\n",
       " 't796',\n",
       " 't9jg',\n",
       " 'taet',\n",
       " 'tbxs',\n",
       " 'tbz9',\n",
       " 'tc85',\n",
       " 'tch7',\n",
       " 'tdgc',\n",
       " 'tf82',\n",
       " 'tfpb',\n",
       " 'tpr9',\n",
       " 'tspc',\n",
       " 'txdx',\n",
       " 'ty73',\n",
       " 'tzxk',\n",
       " 'u23x',\n",
       " 'u4td',\n",
       " 'u7sg',\n",
       " 'u9c7',\n",
       " 'uakk',\n",
       " 'ub7y',\n",
       " 'ubku',\n",
       " 'uf44',\n",
       " 'uhbd',\n",
       " 'up4x',\n",
       " 'upu8',\n",
       " 'uqb3',\n",
       " 'uqpd',\n",
       " 'uqzc',\n",
       " 'urrt',\n",
       " 'uxeu',\n",
       " 'x3kk',\n",
       " 'x3tt',\n",
       " 'x4qx',\n",
       " 'x7yz',\n",
       " 'x8yk',\n",
       " 'xacf',\n",
       " 'xbes',\n",
       " 'xd2h',\n",
       " 'xdjp',\n",
       " 'xg2q',\n",
       " 'xpby',\n",
       " 'xpyb',\n",
       " 'xscu',\n",
       " 'xuht',\n",
       " 'xxbu',\n",
       " 'xz8u',\n",
       " 'y2ds',\n",
       " 'y86a',\n",
       " 'y8bg',\n",
       " 'y999',\n",
       " 'y9cp',\n",
       " 'ydpf',\n",
       " 'yfsj',\n",
       " 'yg2p',\n",
       " 'ygxx',\n",
       " 'ykp8',\n",
       " 'yx9c',\n",
       " 'yyhr',\n",
       " 'z2br',\n",
       " 'z3hq',\n",
       " 'z3xg',\n",
       " 'z6a8',\n",
       " 'z8d2',\n",
       " 'z8fr',\n",
       " 'z996',\n",
       " 'z9k2',\n",
       " 'zasx',\n",
       " 'zcfb',\n",
       " 'zcka',\n",
       " 'zddu',\n",
       " 'zhp6',\n",
       " 'zhqp',\n",
       " 'zjcu',\n",
       " 'zjzb',\n",
       " 'zk9p',\n",
       " 'zkcc',\n",
       " 'zku9',\n",
       " 'zrqy',\n",
       " 'ztrf']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ans=[]\n",
    "for i in range(len(Y_testfilename)):\n",
    "    Y_ans.append(Y_testfilename[i][11:15])\n",
    "Y_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['237j',\n",
       " '24je',\n",
       " '25r7',\n",
       " 'z6dr',\n",
       " '29r5',\n",
       " '2a8c',\n",
       " '2a8f',\n",
       " '2aej',\n",
       " '2crr',\n",
       " '2q33',\n",
       " '2hk2',\n",
       " '2r43',\n",
       " '2u65',\n",
       " '2xa3',\n",
       " '2zc2',\n",
       " '35jf',\n",
       " '36g7',\n",
       " '378c',\n",
       " '377r',\n",
       " '3959',\n",
       " '3adk',\n",
       " '3gkf',\n",
       " '3hb3',\n",
       " '3xyq',\n",
       " 'c48q',\n",
       " '47xh',\n",
       " '47zh',\n",
       " '4a29',\n",
       " '4a65',\n",
       " '4cse',\n",
       " '4dje',\n",
       " '4dhs',\n",
       " '4e9a',\n",
       " '4g2y',\n",
       " '4jz6',\n",
       " '4ktz',\n",
       " '4p6g',\n",
       " '4q62',\n",
       " '4qdf',\n",
       " '4r2z',\n",
       " '4rj7',\n",
       " 'fz2u',\n",
       " '43ak',\n",
       " '4t4e',\n",
       " '548u',\n",
       " '577p',\n",
       " '58y9',\n",
       " '5agj',\n",
       " '5epp',\n",
       " '5hsy',\n",
       " '5gyr',\n",
       " '5rjb',\n",
       " '5sds',\n",
       " '5uzc',\n",
       " '5z8h',\n",
       " '63kt',\n",
       " '63ug',\n",
       " '649p',\n",
       " '65bh',\n",
       " '6754',\n",
       " '67db',\n",
       " '67e3',\n",
       " '68q7',\n",
       " '69g2',\n",
       " '6c2h',\n",
       " '6dgc',\n",
       " '6e7h',\n",
       " '6ecz',\n",
       " '6f5f',\n",
       " '6gkf',\n",
       " '6kbc',\n",
       " '6r9b',\n",
       " '6rs8',\n",
       " '6y8k',\n",
       " '6zrf',\n",
       " '7857',\n",
       " '78ay',\n",
       " '78f2',\n",
       " '78sr',\n",
       " '7ba8',\n",
       " '7d8d',\n",
       " '7eg3',\n",
       " '7gdb',\n",
       " '7hkb',\n",
       " '7kgr',\n",
       " '7kut',\n",
       " '7p33',\n",
       " '7p7u',\n",
       " '7r3t',\n",
       " '7eur',\n",
       " '7th7',\n",
       " '7zes',\n",
       " '83gd',\n",
       " '83h4',\n",
       " '854y',\n",
       " '3ak9',\n",
       " '8b49',\n",
       " '8uzb',\n",
       " '8cz7',\n",
       " '8ecs',\n",
       " '8fhj',\n",
       " '3frr',\n",
       " '8h2p',\n",
       " '8jkx',\n",
       " '8js4',\n",
       " '8tdg',\n",
       " '8g6a',\n",
       " '8q7u',\n",
       " '8rrk',\n",
       " '835t',\n",
       " '8u6p',\n",
       " '8x9k',\n",
       " '8xzp',\n",
       " '8y9f',\n",
       " '8ycj',\n",
       " 'g5p4',\n",
       " '9dhe',\n",
       " '3htk',\n",
       " '9tk3',\n",
       " '9qkp',\n",
       " '9z7f',\n",
       " 'a2jr',\n",
       " 'a64z',\n",
       " 'a7eg',\n",
       " 'a9ut',\n",
       " 'aqk3',\n",
       " 'acxp',\n",
       " 'at7e',\n",
       " 'ae7z',\n",
       " 'aear',\n",
       " 'ajpp',\n",
       " 'ajty',\n",
       " 'ak2f',\n",
       " 'arcp',\n",
       " 'asr3',\n",
       " 'a5z4',\n",
       " 'atpp',\n",
       " 'ax7g',\n",
       " 'b22r',\n",
       " 'b3hk',\n",
       " 'b4p9',\n",
       " 'b54e',\n",
       " 'b6zu',\n",
       " 'ba3t',\n",
       " 'bbat',\n",
       " 'bc4c',\n",
       " 'bc6c',\n",
       " 'bcfc',\n",
       " 'bdbp',\n",
       " 'betp',\n",
       " 'bfrx',\n",
       " 'brt5',\n",
       " 'bxye',\n",
       " '6y7h',\n",
       " 'c2ad',\n",
       " 'cjjh',\n",
       " 'c8rz',\n",
       " 'cdjh',\n",
       " 'c9qd',\n",
       " 'k9sa',\n",
       " 'cakp',\n",
       " 'cbue',\n",
       " 'ccfr',\n",
       " 'ccpk',\n",
       " 'ce2x',\n",
       " 'cfg5',\n",
       " 'cfsk',\n",
       " 'fjsy',\n",
       " 'cqeb',\n",
       " 'crjx',\n",
       " 'csf5',\n",
       " 'cypx',\n",
       " 'dh3f',\n",
       " 'd39c',\n",
       " 'd5cy',\n",
       " 'd5xp',\n",
       " 'd8yh',\n",
       " 'd93z',\n",
       " 'dbg3',\n",
       " 'dbhx',\n",
       " 'dgs4',\n",
       " 'dhfh',\n",
       " 'djzq',\n",
       " 'gug5',\n",
       " 'dpfg',\n",
       " 'dqtr',\n",
       " 'dqxt',\n",
       " 'dqz5',\n",
       " 'dsjt',\n",
       " 'dtja',\n",
       " 'dyc4',\n",
       " 'dz7s',\n",
       " 'e468',\n",
       " 'e6kk',\n",
       " 'ebku',\n",
       " 'ed9p',\n",
       " 'efea',\n",
       " 'efj7',\n",
       " 'eg64',\n",
       " 'egzb',\n",
       " 'ek3b',\n",
       " 'ekjp',\n",
       " 'ekt3',\n",
       " 'eqta',\n",
       " 'es6c',\n",
       " 'eu76',\n",
       " 'eu8r',\n",
       " 'ex69',\n",
       " 'exex',\n",
       " 'f2f7',\n",
       " 'fx73',\n",
       " 'fcs2',\n",
       " 'fxuq',\n",
       " 'fx8s',\n",
       " 'fkkf',\n",
       " 'frgf',\n",
       " 'fxr6',\n",
       " 'fygj',\n",
       " 'fjhj',\n",
       " 'g4uz',\n",
       " 'g837',\n",
       " 'g87c',\n",
       " 'g9bp',\n",
       " '3qg9',\n",
       " '3byp',\n",
       " 'gc6g',\n",
       " 'gc5k',\n",
       " 'g27z',\n",
       " 'ggue',\n",
       " 'gj3a',\n",
       " 'qk6t',\n",
       " 'qphp',\n",
       " 'grhs',\n",
       " 'gtuz',\n",
       " 'gtt8',\n",
       " 'guku',\n",
       " 'heak',\n",
       " 'h52h',\n",
       " 'h5tf',\n",
       " 'h67g',\n",
       " 'h6gb',\n",
       " 'h8xp',\n",
       " 'ha5j',\n",
       " 'hcby',\n",
       " 'h9xh',\n",
       " 'hdu6',\n",
       " 'hege',\n",
       " 'hey8',\n",
       " 'hh33',\n",
       " 'hr2k',\n",
       " 'hxud',\n",
       " 'hyjx',\n",
       " 'j2z7',\n",
       " 'j3xy',\n",
       " 'j42f',\n",
       " 'j44d',\n",
       " 'j4z4',\n",
       " 'j899',\n",
       " 'j8uc',\n",
       " 'jb2e',\n",
       " 'jbgk',\n",
       " 'jc2b',\n",
       " 'jes5',\n",
       " 'jetc',\n",
       " 'jkuc',\n",
       " 'js3t',\n",
       " 'jt8f',\n",
       " 'k4t8',\n",
       " 'k5q7',\n",
       " 'k6b5',\n",
       " 'k9bd',\n",
       " 'kafq',\n",
       " 'kbyk',\n",
       " 'kc2d',\n",
       " 'keeq',\n",
       " 'kkc8',\n",
       " 'khtz',\n",
       " 'kq9e',\n",
       " 'ktej',\n",
       " 'kqcg',\n",
       " 'pr3j',\n",
       " 'p5a9',\n",
       " 'p87g',\n",
       " 'pdte',\n",
       " 'pf2f',\n",
       " 'pj4f',\n",
       " 'pj6a',\n",
       " 'prtd',\n",
       " 'puhf',\n",
       " 'puh8',\n",
       " 'pzt7',\n",
       " 'q4f2',\n",
       " 'q4ut',\n",
       " 'q5yj',\n",
       " 'quzx',\n",
       " 'qaah',\n",
       " 'qaet',\n",
       " 'du7k',\n",
       " 'qque',\n",
       " 'qd7d',\n",
       " 'qg96',\n",
       " 'qh5s',\n",
       " 'qhak',\n",
       " 'qk5p',\n",
       " 'qtka',\n",
       " 'qtrx',\n",
       " 'qu2g',\n",
       " 'qu8b',\n",
       " 'qx9q',\n",
       " 'qxpx',\n",
       " 'r2hh',\n",
       " 'r34u',\n",
       " 'y4h8',\n",
       " 'r4k5',\n",
       " 'r62c',\n",
       " 'r987',\n",
       " 'rag2',\n",
       " 'rcs6',\n",
       " 'cf48',\n",
       " 'rfe7',\n",
       " 'f9ce',\n",
       " 'rger',\n",
       " 'fhgp',\n",
       " 'rhpb',\n",
       " 'fhps',\n",
       " 'r5ft',\n",
       " 'fte2',\n",
       " 'ryhu',\n",
       " 'rzeb',\n",
       " 's46s',\n",
       " 's48u',\n",
       " '5dbb',\n",
       " 's5bj',\n",
       " 's743',\n",
       " 's7s3',\n",
       " 's83g',\n",
       " 's9cf',\n",
       " 'sbbz',\n",
       " 'sjzs',\n",
       " 'spu7',\n",
       " 'sah3',\n",
       " 'ss6k',\n",
       " 'sxhe',\n",
       " 'sy4u',\n",
       " 'sz6k',\n",
       " 't47e',\n",
       " 't796',\n",
       " 't9jg',\n",
       " 'ta8t',\n",
       " 'tbxs',\n",
       " 'ubz9',\n",
       " 'tc85',\n",
       " 'tch7',\n",
       " 'tugc',\n",
       " 'tf82',\n",
       " 'tfub',\n",
       " 'tpx9',\n",
       " 'tspc',\n",
       " 'txdx',\n",
       " 'ty73',\n",
       " 'tzxk',\n",
       " 'u233',\n",
       " 'uztd',\n",
       " 'u7sg',\n",
       " 'u9c7',\n",
       " 'uakk',\n",
       " 'ub7y',\n",
       " 'ubku',\n",
       " 'uf44',\n",
       " 'uhbd',\n",
       " 'ug4h',\n",
       " 'upu8',\n",
       " 'uqb3',\n",
       " 'tqpd',\n",
       " 'uqzc',\n",
       " 'trrt',\n",
       " 'uheu',\n",
       " 'x3kk',\n",
       " 'k3tt',\n",
       " 'x4qx',\n",
       " 'x7yz',\n",
       " 'x8yk',\n",
       " 'xacf',\n",
       " 'xbes',\n",
       " 'xd2h',\n",
       " 'xdjp',\n",
       " 'xq4q',\n",
       " 'xpby',\n",
       " 'xpyb',\n",
       " 'xscu',\n",
       " 'xuht',\n",
       " 'xxbu',\n",
       " 'xz8u',\n",
       " 'y2ds',\n",
       " 'y86a',\n",
       " 'y8g9',\n",
       " 'y999',\n",
       " 'y9ep',\n",
       " 'ydpf',\n",
       " 'yfsj',\n",
       " 'yg2p',\n",
       " 'ygxx',\n",
       " 'ykp8',\n",
       " 'yk9e',\n",
       " 'yyhr',\n",
       " 'z2br',\n",
       " 'z3hq',\n",
       " 'z3xg',\n",
       " 'z6a8',\n",
       " 'z8d2',\n",
       " 'z8rr',\n",
       " 'z996',\n",
       " 'z9k2',\n",
       " 'zas4',\n",
       " 'zcfb',\n",
       " 'zcka',\n",
       " 'zedu',\n",
       " 'zhp6',\n",
       " 'zhqp',\n",
       " 'zjsu',\n",
       " 'zjzb',\n",
       " 'zk9p',\n",
       " 'zkcc',\n",
       " 'zku9',\n",
       " 'zeqy',\n",
       " 'zrrr']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_df = pd.DataFrame({'id': np.array(Y_ans), 'class':y_test_pred}).sort_values(by='id')\n",
    "y_test_pred_df.to_csv('./submissions/{}.csv'.format(model_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
